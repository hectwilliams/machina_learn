""" Structure of Markov Decision Process(MDP).
"""

transition_probabilities = [
    # s0
    [
        [0.7, 0.3, 0.0], # a0->s0, a0->s1, a0->s2
        [1.0, 0.0, 0.0], # a1->s0, a1->s1, a1->s2
        [0.8, 0.2, 0.0], # a2->s0, a2->s1, a2->s2
    ],
    # s1
    [
        [0.0, 1.0, 0.0], # a0->s0, a0->s1, a0->s2
        None, 
        [0.0, 0.0, 1.0] # a2->s0, a2->s1, a2->s2
    ],
    # s2
    [
        None, 
        [0.8, 0.1, 0.1], # a1->s0, a1->s1, a1->s2
        None 
    ]
]

rewards = [
    # s0
    [
        [+10, 0, 0],
        [0, 0, 0],
        [0, 0, 0],
    ],
    # s1
    [
        [0, 0, 0],
        [0, 0, 0],
        [0, 0, -50]
    ],
    # s2
    [
        [0, 0, 0],
        [+40, 0, 0],
        [0, 0, 0]
    ]
]

possible_actions = [
    # s0
    [0, 1, 2],
    # s1
    [0, 2],
    # s2
    [1]
]